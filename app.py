import streamlit as st
from PIL import Image
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
import gdown
import os
import datetime

# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³
MODEL_PATH = "arch_classifier_model.h5"
MODEL_VERSION = "final_streamlit_export"
GDRIVE_URL = "https://drive.google.com/uc?id=1-0jLv-ahm5Vs06Q7aXE3N4SS22R4HOAh"
MODEL_UPDATE_DATE = "2025/05/29"

# ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã° Google Drive ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
if not os.path.exists(MODEL_PATH):
    st.warning("ğŸ“¦ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™â€¦")
    try:
        gdown.download(GDRIVE_URL, MODEL_PATH, quiet=False)
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ï¼š{e}")
        st.stop()

# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
try:
    model = load_model(MODEL_PATH, compile=False)
    timestamp = os.path.getmtime(MODEL_PATH)
    modified_date = datetime.datetime.fromtimestamp(timestamp).strftime('%Y/%m/%d %H:%M')
    st.caption(f"ğŸ§  ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ï¼š{MODEL_VERSION}ï¼ˆæ›´æ–°æ—¥æ™‚ï¼š{modified_date}ï¼‰")
except Exception as e:
    st.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ï¼š{e}")
    st.stop()

# ã‚¢ãƒ—ãƒªã‚¿ã‚¤ãƒˆãƒ«
st.title("è¶³å‹ã‚¤ãƒ³ã‚½ãƒ¼ãƒ«è¨ºæ–­ã‚¢ãƒ—ãƒªï¼ˆResNetãƒ™ãƒ¼ã‚¹AIç”»åƒåˆ†é¡ï¼‰")

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
leg_shape = st.radio("è„šã®å½¢çŠ¶ã‚’é¸ã‚“ã§ãã ã•ã„", ["Oè„š", "Xè„š", "æ­£å¸¸"])
has_bunion = st.radio("å¤–åæ¯è¶¾ã®æœ‰ç„¡", ["ã‚ã‚Š", "ãªã—"])

# ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("è¶³è£ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆ.jpg/.pngï¼‰", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    try:
        image = Image.open(uploaded_file).convert("RGB")
    except Exception as e:
        st.error(f"ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ï¼š{e}")
        st.stop()

    st.image(image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸè¶³è£ç”»åƒ", use_column_width=True)

    # å‰å‡¦ç†
    image_resized = image.resize((224, 224))
    img_array = img_to_array(image_resized) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    # äºˆæ¸¬
    prediction = model.predict(img_array)
    predicted_index = np.argmax(prediction)

    # ãƒ©ãƒ™ãƒ«å®šç¾©
    label_map = {0: "High", 1: "Normal", 2: "Flat"}
    arch_label = label_map[predicted_index]

    st.markdown(f"### ğŸ§  AIè¨ºæ–­çµæœï¼š**{arch_label}**")

    # ãƒ‘ã‚¿ãƒ¼ãƒ³IDï¼ˆ12åˆ†é¡ï¼‰
    def get_pattern_id(arch, leg, bunion):
        arch_map = {"Flat": 0, "High": 1, "Bunion": 2, "Normal": 3}
        leg_map = {"Oè„š": 0, "Xè„š": 1, "æ­£å¸¸": 2}
        if bunion == "ã‚ã‚Š":
            arch = "Bunion"
        return arch_map[arch] * 3 + leg_map[leg] + 1

    pattern_id = get_pattern_id(arch_label, leg_shape, has_bunion)
    st.success(f"ğŸ¦¶ ã‚ãªãŸã®è¶³å‹åˆ†é¡ãƒ‘ã‚¿ãƒ¼ãƒ³IDï¼š**{pattern_id} / 12**")

    # æ¨å¥¨ã‚¤ãƒ³ã‚½ãƒ¼ãƒ«è¡¨ç¤º
    st.info(f"ã“ã®ã‚¿ã‚¤ãƒ—ã«ãŠã™ã™ã‚ã®ã‚¤ãƒ³ã‚½ãƒ¼ãƒ«ï¼š**ã‚¤ãƒ³ã‚½ãƒ¼ãƒ«{pattern_id}ç•ª** ã‚’ãŠè©¦ã—ãã ã•ã„ï¼")


